# =============================================================================
# AI API Keys Configuration
# =============================================================================
# The orchestrator supports multiple AI providers. At minimum, OPENAI_API_KEY
# is required. Add any optional provider keys you want to use.
#
# USAGE:
# 1. Copy this file to .env
# 2. Uncomment and set the API keys you want to use
# 3. The orchestrator will automatically load from .env file and environment variables
# 
# NOTE: Environment variables take precedence over .env file values.

# =============================================================================
# REQUIRED KEYS
# =============================================================================
# OpenAI API Configuration (REQUIRED)
OPENAI_API_KEY=<your-openai-api-key>
OPENAI_API_MODEL=gpt-4o-mini

# =============================================================================
# OPTIONAL PROVIDER KEYS
# =============================================================================
# Uncomment and set the API keys for providers you want to use:

# Anthropic Claude
# ANTHROPIC_API_KEY=<your-anthropic-api-key>

# Google Gemini (use either key format)
# GOOGLE_API_KEY=<your-google-api-key>
# GOOGLE_AI_API_KEY=<your-google-ai-api-key>

# Cohere
# COHERE_API_KEY=<your-cohere-api-key>

# Hugging Face (use either key format)
# HUGGINGFACE_API_KEY=<your-huggingface-api-key>
# HF_TOKEN=<your-hf-token>

# Mistral AI
# MISTRAL_API_KEY=<your-mistral-api-key>

# Groq
# GROQ_API_KEY=<your-groq-api-key>

# =============================================================================
# ROUTING STRATEGY CONFIGURATION
# =============================================================================
# Configure load balancing and routing strategies for multiple providers
# Uses unified provider:model configuration format

# Random Provider Configuration (for testing)
RANDOM_API_MODEL=random
RANDOM_API_KEY=random

# Default routing strategy (backoff to single provider with model)
ROUTING_STRATEGY=backoff
ROUTING_CONFIG=openai:gpt-4o-mini

# Alternative routing configurations (uncomment to use):

# Round-robin across multiple providers with their models:
# ROUTING_STRATEGY=roundrobin
# ROUTING_CONFIG=openai:gpt-4o-mini,anthropic:claude-3-sonnet,gemini:gemini-pro

# Priority order (try cheapest first):
# ROUTING_STRATEGY=priority
# ROUTING_CONFIG=gemini:gemini-pro,openai:gpt-4o-mini,anthropic:claude-3-sonnet

# Weighted distribution with provider:model:weight format:
# ROUTING_STRATEGY=weighted
# ROUTING_CONFIG=openai:gpt-4o-mini:0.5,anthropic:claude-3-sonnet:0.3,gemini:gemini-pro:0.2

# Test with random provider (no API keys needed):
# ROUTING_STRATEGY=backoff
# ROUTING_CONFIG=random:random